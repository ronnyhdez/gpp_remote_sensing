---
title: "Results and conclussions"
description: |
  MODIS products can understimate GPP in Santa Rosa National Park Tropical Dry Forest
site: distill::distill_website
output:
  distill::distill_article:
    code_folding: true
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)

# Libraries
library(readr)
library(dplyr)
library(ggplot2)
library(janitor)
library(lubridate)
library(visdat)
library(corrplot)
library(tidyr)
library(rmarkdown)
library(tidymodels)
library(report)
library(cowplot)

# Import data sets
precipitation <- 
  read_csv("data/hardvard_dataverse_tropidry/Daily_Precipitation_2013_to_2016.csv") %>% 
  clean_names() %>% 
  slice(-1) %>% 
  mutate(date = ymd(date),
         do_y = as.numeric(do_y),
         precip = as.numeric(precip))

biomet <- 
  read_csv("data/hardvard_dataverse_tropidry/Micrometeorological_Biomet_Parameters_2013_to_2016.csv") %>% 
  clean_names() %>% 
  slice(-1) %>% 
  mutate(date = ymd_hm(date)) %>% 
  mutate(across(where(is.character), as.numeric))

monthly_gpp <- 
  read_csv("data/hardvard_dataverse_tropidry/Monthly_NEE_GPP_Reco_2013_to_2016.csv") %>% 
  clean_names() %>% 
  slice(-1) %>% 
  unite(col = date, year, month, sep = "-") %>% 
  mutate(date = paste0(date, "-1"),
         date = ymd(date)) %>% 
  select(-date_1, -date_2) %>% 
  mutate(across(where(is.character), as.numeric))

ndvi_moha <- 
  readxl::read_xlsx("data/hardvard_dataverse_tropidry/final -NDVI- smoothed -complete.xlsx") %>% 
  clean_names()

modis_gpp <- 
  read_csv("data/modis-gpp-sr/modis-sr-MYD17A2H-006-results.csv") %>% 
  clean_names() %>% 
  select(date, myd17a2h_006_gpp_500m, 
         myd17a2h_006_psn_qc_500m_modland_description,
         myd17a2h_006_psn_qc_500m_cloud_state_description,
         myd17a2h_006_psn_qc_500m_scf_qc_description) %>% 
  rename(gpp = myd17a2h_006_gpp_500m,
         modland_description = myd17a2h_006_psn_qc_500m_modland_description,
         cloud_state_description = myd17a2h_006_psn_qc_500m_cloud_state_description,
         scf_qc_description = myd17a2h_006_psn_qc_500m_scf_qc_description) %>% 
  mutate(gpp = gpp * 10)

modis_indices <- 
  read_csv("data/modis-indices-sr/modis-indices-sr-MOD13Q1-006-results.csv") %>% 
  clean_names() %>% 
  select(date, mod13q1_006_250m_16_days_evi, 
         mod13q1_006_250m_16_days_ndvi, 
         mod13q1_006_250m_16_days_vi_quality,
         mod13q1_006_250m_16_days_pixel_reliability,
         mod13q1_006_250m_16_days_pixel_reliability_modland_description) %>% 
  rename(evi = mod13q1_006_250m_16_days_evi,
         ndvi = mod13q1_006_250m_16_days_ndvi,
         vi_quality = mod13q1_006_250m_16_days_vi_quality,
         pixel_reliability = mod13q1_006_250m_16_days_pixel_reliability,
         reliability_modland_description =
           mod13q1_006_250m_16_days_pixel_reliability_modland_description)
```

<!-- 5. Results (including Discussion ~500 words) -->

<!-- Results and Discussion – Be selective and only show a reasonable number of  -->
<!-- quality graphs that describe your results. Discuss each graph (or group of  -->
<!-- graphs) with a separate paragraph that makes references to the figures (or  -->
<!-- tables) that you are talking about. Tell people what they see in the graph,  -->
<!-- point out interesting relationships, explain how they can be biologically  -->
<!-- interpreted, and/or what the practical applications of these findings are. -->

<!-- [For the draft submission, you are somewhat limited to complete this section. -->
<!-- You may apply what you learned in Labs 1 through 5 where applicable and useful. -->
<!-- Leave the rest for completion for the final submission. If you have some ideas  -->
<!-- which advanced multivariate methods you want to use here, you can briefly  -->
<!-- describe your plans to receive some feedback on that.] -->

<!-- Conclusions, About, References – You may add these as additional pages,  -->
<!-- paragraphs or footnotes.  -->

## Results

### How is the relation between MODIS EVI NDVI & GPP products?

We are using products from MODIS which are: EVI, NDVI and GPP. These are already
calculated values that are available to users. These products comes with 
variables that flags low quality values. In this case we have a data set with 
flags for GPP and a data set with flags for the indices EVI and NDVI.

All values with flags that advertised low quality data points were remove from
both data sets. Then a pearson correlation was performed to explore the
relation between GPP and NDVI, and GPP with EVI. 

```{r MODIS data quality filtering}
## Filter observations with good quality
## This takes from 94 observations to 53 observations. Remove 41 observations
modis_indices_clean <- modis_indices %>% 
  filter(reliability_modland_description == "Good data, use with confidence") %>% 
  select(date, ndvi, evi) #%>% 
  # mutate(week = week(date),
  #        year = year(date))

## Filter observations with good quality
## This takes from 183 observations to 114. Remove 69 observations.
modis_gpp_clean <- modis_gpp %>% 
  filter(modland_description == "Good quality",
         cloud_state_description == "Significant clouds NOT present (clear)",
         scf_qc_description == "Very best possible") %>% 
  select(date, gpp) #%>% 
  # mutate(week = week(date),
  #        year = year(date))

modis_join <- modis_gpp_clean %>% 
  full_join(modis_indices_clean, by = c("date"))
```

As validation for the relations between products from MODIS, I proceed to 
compare NDVI against GPP to check how is the relation between these variables.

```{r, fig.cap = "Relation between NDVI and GPP products from MODIS for the Santa Rosa National Park"}
#### Relation between NDVI and GPP from MODIS
gpp_ndvi <- modis_join %>% 
  ggplot(aes(x = ndvi, y = gpp)) +
  geom_point(color = "#FF3A1D", size = 3.5) +
  geom_smooth(method = "lm", color = "#4E5C68") +
  theme_light(base_size = 12) +
  theme(axis.text.x = element_text(angle = 90, h = 1)) +
  labs(x = "NDVI", y = "GPP (mgm-2s-1)")

#### Relation between EVI and GPP from MODIS
gpp_evi <- modis_join %>% 
  ggplot(aes(x = evi, y = gpp)) +
  geom_point(color = "#FF3A1D", size = 3.5) +
  geom_smooth(method = "lm", color = "#4E5C68") +
  theme_light(base_size = 12) +
  theme(axis.text.x = element_text(angle = 90, h = 1)) +
  labs(x = "EVI", y = "GPP (mgm-2s-1)")

## Arrange both plots in one figure:
plot_grid(gpp_ndvi, gpp_evi, labels = c('A', 'B'), label_size = 12)
```

```{r corr results MODIS products}
ndvi_corr_test <- cor.test(modis_join$ndvi, modis_join$gpp)
evi_corr_test <- cor.test(modis_join$evi, modis_join$gpp)

# Check the report of the result
# report(ndvi_corr_test)
# report(evi_corr_test)
```

The Pearson's product-moment correlation between **NDVI and GPP** products from
MODIS is positive and statistically significant. (r = 0.81, 95% CI [0.65, 0.90],
t(34) = 8.01, p < .001). For **EVI and GPP** the Pearson's product-moment 
correlation is is positive, and statistically significant (r = 0.70, 
95% CI [0.48, 0.84], t(34) = 5.70, p < .001)

 - NDVI have a higher positive correlation with GPP product from MODIS than EVI.
 
### How is the relation between MODIS products and GPP estimated in-situ?

Now that I checked the relation between the MODIS products, I can compared and
evaluate the relation between the MODIS products with the GPP estimated in-situ.
The clean data sets from MODIS products were used here altogether with the GPP
data set with the estimations per month from Santa Rosa National Park.

```{r}
average_gpp <- modis_gpp_clean %>% 
  group_by(zoo::as.yearmon(date)) %>% 
  summarise(
    average_modis_gpp = mean(gpp)
  ) %>% 
  rename(month_year = `zoo::as.yearmon(date)`)

modis_in_situ_gpp <- monthly_gpp %>% 
  mutate(month_year = zoo::as.yearmon(date)) %>% 
  select(month_year, average_gpp) %>% 
  full_join(average_gpp, by = "month_year")

modis_in_situ_gpp %>% 
  ggplot(aes(x = average_gpp, y = average_modis_gpp)) +
  geom_point() +
  geom_smooth(method = "lm")

cor.test(modis_in_situ_gpp$average_gpp, modis_in_situ_gpp$average_modis_gpp)
```

### Does MODIS NDVI correlates with GPP in-situ?

```{r}
ndvi_gpp_in_situ <- modis_indices_clean %>% 
  group_by(zoo::as.yearmon(date)) %>% 
  summarise(
    ndvi_mean = mean(ndvi, na.rm = TRUE),
    evi_mean = mean(evi, na.rm = TRUE)
  ) %>% 
  rename(month_year = `zoo::as.yearmon(date)`) %>%
  full_join(modis_in_situ_gpp, by = "month_year")

ndvi_gpp_in_situ %>% 
  ggplot(aes(x = ndvi_mean, y = average_gpp)) +
  geom_point() +
  geom_smooth(method = "lm")

cor.test(ndvi_gpp_in_situ$ndvi_mean, ndvi_gpp_in_situ$average_gpp)
```

### Does MODIS EVI correlates with GPP in-situ?

```{r}
ndvi_gpp_in_situ %>% 
  ggplot(aes(x = evi_mean, y = average_gpp)) +
  geom_point() +
  geom_smooth(method = "lm")

cor.test(ndvi_gpp_in_situ$evi_mean, ndvi_gpp_in_situ$average_gpp)
```

### Which are the values with the largest residuals?

If I obtain those values with the largest residuals, then I can check the date
from those values, and validate if they have something in common. This could
give us clues about when an index works very well or when it has some bias.

```{r}
## Create the linear model and check results
fit <- lm(average_gpp ~ evi_mean, data = ndvi_gpp_in_situ)
summary(fit)
```


```{r}
## Obtain data used in the model (without NA's) to paste residuals and explore
## if there is a pattern of largest residuals in specific months
model_observations <- fit[["model"]]
model_residuals <- fit[["residuals"]] %>% 
  as.data.frame() %>% 
  rename("residuals" = ".")

# Create dataset
observations_residuals <- model_observations %>% 
  left_join(ndvi_gpp_in_situ, by = c("average_gpp", "evi_mean")) %>% 
  select(-average_modis_gpp, -ndvi_mean) %>% 
  bind_cols(model_residuals)

# Plot residuals through time
observations_residuals %>% 
  ggplot(aes(x = month_year, y = residuals)) +
  geom_point() +
  geom_smooth()

## Take biomet variables to validate if there is a similar pattern:
biomet_summarized <- biomet %>% 
  group_by(zoo::as.yearmon(date)) %>% 
  summarise(
    par_incoming = mean(par_incoming, na.rm = TRUE),
    swc = mean(swc, na.rm = TRUE),
    vpd = mean(vpd, na.rm = TRUE),
    r_h = mean(r_h, na.rm = TRUE),
    tair = mean(tair, na.rm = TRUE),
    le = mean(le, na.rm = TRUE),
    h = mean(h, na.rm = TRUE)
  ) %>% 
  rename(month_year = `zoo::as.yearmon(date)`)

check <- observations_residuals %>% 
  left_join(biomet_summarized, by = "month_year") %>% 
  select(-month_year) #%>% 
  # cor()

# library(PerformanceAnalytics)
# chart.Correlation(check, histogram = TRUE, method = "pearson")
```

### Which meteorological variable have more influence in GPP in-situ?

```{r}

```

### MODIS NDVI, EVI & GPP trends over time

```{r fig.cap = "GPP trends over the years for MODIS and in-situ data. Despite having similar trends, range is higher for in-situ data than the MODIS derived GPP"}
# Plot with both GPP's
rec_monthly_gpp <- monthly_gpp %>% 
  select(date, average_gpp) %>% 
  rename(gpp = average_gpp) %>% 
  mutate(origin = "in_situ")

rec_modis_gpp <- modis_gpp %>% 
  select(date, gpp) %>% 
  mutate(date = floor_date(date, "month")) %>% 
  group_by(date) %>% 
  summarise(
    gpp = mean(gpp, na.rm = TRUE)
  ) %>% 
  mutate(origin = "modis") %>% 
  filter(date > ymd("2013-04-30"))

rec_both <- bind_rows(rec_monthly_gpp, rec_modis_gpp)

## Correlation trends between both GPP's`
rec_both %>% 
  ggplot(aes(x = date, y = gpp, group = origin)) +
  geom_line(aes(color = origin), size = 1) +
  theme_linedraw(base_size = 12) +
  scale_x_date(date_labels = "%b%Y", breaks = "months") +
  theme(axis.text.x = element_text(angle = 70, h = 1)) +
  labs(x = "Date", y = "GPP (mgm-2s-1)", color = "GPP source")
```

### PCA for meteorological variables

TODO: Implement nice PCA plot!!!
```{r}
# nrow(biomet)
# biomet %>% drop_na() %>% nrow()
biomet_pca <- biomet %>% 
  select(-date, -year, -do_y, -hour) %>% 
  drop_na() %>% 
  princomp(cor = T)

# biplot(biomet_pca)
```

### Gradient analysis

```{r}

```


#### Regression trees

This section is still a **Work In Progress**. The objective is to apply a
regression Random Forest using the meteorological variables as predictors of 
GPP. After the evaluation of the predictions also a variable importance
analysis will be run.

Given that GPP observations are monthly, this reduces the total amount of 
observations available, so bootstrapping is applied to the regression random
forest.

```{r}
ndvi_summarized <- ndvi_moha %>% 
  mutate(year_mon = zoo::as.yearmon(date)) %>% 
  group_by(year_mon) %>% 
  summarize(
    ndvi_mean = mean(ndvi, na.rm = TRUE),
    ndvi_sd = sd(ndvi, na.rm = TRUE)
  )

biomet_summarized <- biomet %>% 
  mutate(year_mon = zoo::as.yearmon(date)) %>% 
  group_by(year_mon) %>% 
  summarize(
    # sd_par_incoming = sd(par_incoming, na.rm = TRUE), 
    # sd_swc          = sd(swc, na.rm = TRUE), 
    # sd_vpd          = sd(vpd, na.rm = TRUE), 
    # sd_r_h          = sd(r_h, na.rm = TRUE), 
    # sd_tair         = sd(tair, na.rm = TRUE), 
    # sd_nee          = sd(nee, na.rm = TRUE), 
    # sd_le           = sd(le, na.rm = TRUE), 
    # sd_h            = sd(h, na.rm = TRUE),
    mean_par_incoming = sd(par_incoming, na.rm = TRUE), 
    mean_swc          = sd(swc, na.rm = TRUE), 
    mean_vpd          = sd(vpd, na.rm = TRUE), 
    mean_r_h          = sd(r_h, na.rm = TRUE), 
    mean_tair         = sd(tair, na.rm = TRUE), 
    # mean_nee          = sd(nee, na.rm = TRUE), 
    mean_le           = sd(le, na.rm = TRUE), 
    mean_h            = sd(h, na.rm = TRUE)
  )

summarize_dataset <- monthly_gpp %>% 
  mutate(year_mon = zoo::as.yearmon(date)) %>% 
  inner_join(ndvi_summarized) %>% 
  inner_join(biomet_summarized) %>% 
  drop_na()

set.seed(123)
gpp_split <- initial_split(summarize_dataset)
gpp_train <- training(gpp_split)
gpp_test <- testing(gpp_split)

set.seed(123)
gpp_boot <- bootstraps(gpp_train)
gpp_boot

rf_spec <- rand_forest() %>%
  set_mode("regression") %>%
  set_engine("ranger")

rf_spec

gpp_wf <- workflow() %>%
  add_formula(average_gpp ~ .)

gpp_wf


rf_rs <- gpp_wf %>%
  add_model(rf_spec) %>%
  fit_resamples(
    resamples = gpp_boot,
    control = control_resamples(save_pred = TRUE)
  )

rf_rs


## Evaluate model
collect_metrics(rf_rs)
```


## Conclusions




## References

 > James, G., Witten, D., Hastie, T., & Tibshirani, R. (2013). An introduction to statistical learning (Vol. 112, p. 18). New York: springer.
